{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f386463-67b6-4c7f-bfd6-eabb472fb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbfb2c-8a78-4cb6-bcbe-0385e63e4ab9",
   "metadata": {},
   "source": [
    "## Conversion to SimCLRv2 and Converting TF Pretrained Weights\n",
    "Pretrained weights can be found on Google's [repo](https://github.com/google-research/simclr). With conversion scripts linked. Most of the inital work can be found in spijkervet_prototypes.ipynb. This work is to clean up the spaghetti code and turn into modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166a26a8-2db6-4c3a-801e-9cea8557459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from model import save_model, load_optimizer\n",
    "from simclr.modules import LogisticRegression\n",
    "from simclr import SimCLR, SimCLRv2\n",
    "from simclr.modules import get_resnet_pt, get_resnet_v2, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5924409-4624-47a5-8947-3222c62f8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"../config/config.yaml\")\n",
    "\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "    \n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dbf396-7d6c-40d7-8a95-eb5cda64c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': 'CIFAR100',\n",
      " 'dataset_dir': './datasets',\n",
      " 'device': device(type='cuda'),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 400,\n",
      " 'gpus': 4,\n",
      " 'image_size': 224,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'save',\n",
      " 'nodes': 1,\n",
      " 'nr': 0,\n",
      " 'optimizer': 'LARS',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 64}\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 32\n",
    "args.resnet = \"resnet50\"\n",
    "args.epochs = 400\n",
    "args.gpus = 4\n",
    "args.optimizer = 'LARS'\n",
    "args.workers = 64\n",
    "args.dataset = 'CIFAR100'\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8876c5c5-fd92-41e6-bbec-3a57471d7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"unlabeled\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.nodes > 1:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "\n",
    "# Data Transforms happen here.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f7ffc-3f27-46d9-b2a7-a76824c5942e",
   "metadata": {},
   "source": [
    "## SimCLRv2: Self Supervised Learning\n",
    "Modified SimCLR Pytorch code to v2 with Resnet code from converter which includes contrastive head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01870e1-d81a-461a-b2c7-1b7aa0521a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if args.reload:\n",
    "    model_fp = os.path.join(\n",
    "        args.model_path, f\"checkpoint_{args.epoch_num}.tar\"\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "model = model.to(args.device)\n",
    "optimizer, scheduler = load_optimizer(args, model)\n",
    "criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98c3cf-5a65-429a-bd5c-abc345aaa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer, display_every=50):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "    #for step, x_i, x_j in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "        \n",
    "        # Positive pair with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "        \n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % display_every == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        epoch_loss += loss.item()\n",
    "        args.global_step += 1\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573bdad-e6f8-48ef-a72a-7cc0afbccc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    epoch_loss = train(args, train_loader, model, criterion, optimizer, writer)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        save_model(args, model, optimizer)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {epoch_loss / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
    "    )\n",
    "    args.current_epoch += 1\n",
    "\n",
    "save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414383-2ba3-4bbb-a0ce-6987f0926130",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25df3e-329c-4193-9749-3ec0e8359f6c",
   "metadata": {},
   "source": [
    "## SimCLRv2: Fine Tuning From Projection Head\n",
    "v2 paper states that fine tuning should happen from 2nd linear projection layer. Original SimCLR implementation basically throws this away and additionally does not have fine-tuning step from Resnet. Build code to take middle layer of projection then run supervised fine-tuning using cross-entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbfbfb2-f5e8-45a2-ba66-aec8fe6e2c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "simclr_model = SimCLRv2(resnet_depth=50, resnet_width_multiplier=2, sk_ratio=0.0625, \n",
    "                        pretrained_weights='/home/kaipak/models/SimCLRv2/r50_2x_sk1.pth')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model)\n",
    "  # simclr_model_ngpu.n_features = n_features\n",
    "\n",
    "simclr_model = simclr_model_ngpu.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82d5190-bcde-4471-8ecc-03eca5ffc72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions to map all input data X to their latent representations \n",
    "# h that are used in linear evaluation (they only have to be computed once)\n",
    "# Should be part of the processing step before FT.\n",
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, _, z, _ = simclr_model(x, x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabdabf-a637-4283-833e-cd8e894917eb",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "For linear evaluation or fine tuning, since we are now interested in labeling instead of self supervised contrastive learning, we will need to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7817fc03-97b0-4e0f-874f-4054d331c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"train\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"test\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR100(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d677d3-e1cb-4c67-8cbc-a725f50c9136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/195]\t Computing features...\n",
      "Step [20/195]\t Computing features...\n",
      "Step [40/195]\t Computing features...\n",
      "Step [60/195]\t Computing features...\n",
      "Step [80/195]\t Computing features...\n",
      "Step [100/195]\t Computing features...\n",
      "Step [120/195]\t Computing features...\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y, test_X, test_y) = get_features(\n",
    "    simclr_model, train_loader, test_loader, args.device\n",
    ")\n",
    "\n",
    "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6d50c-be46-4d36-b2e8-1381e95aeb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
