{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7525d782-2eab-4104-9850-6e12926c39af",
   "metadata": {},
   "source": [
    "# Initial Experiment and Setup\n",
    "SimCLRv1 notebook code originally from Spjijkervet/SimCLR. Most of the experiments here are an effort to use pretrained weights provided from Google's original implementation with pre-trained weights and conversion to v2. Useful for record, but a bit messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "278b3507-e92e-4e7e-9b41-c9b6c199498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af35abf-716a-42b7-b908-b7b5a70271ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from model import save_model, load_optimizer\n",
    "from simclr.modules import LogisticRegression\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from utils import yaml_config_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db5a605a-109d-4e6a-83e4-a6d7d5931fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"../config/config.yaml\")\n",
    "\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "    \n",
    "args = parser.parse_args([])\n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6fd2616-bd12-46eb-aaa2-819a686a42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': 'CIFAR10',\n",
      " 'dataset_dir': './datasets',\n",
      " 'device': device(type='cuda'),\n",
      " 'epoch_num': 100,\n",
      " 'epochs': 400,\n",
      " 'gpus': 4,\n",
      " 'image_size': 224,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'save',\n",
      " 'nodes': 1,\n",
      " 'nr': 0,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet50',\n",
      " 'seed': 42,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 8}\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 256\n",
    "args.resnet = \"resnet50\"\n",
    "args.epochs = 400\n",
    "args.gpus = 4\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83ffa519-b559-4dc9-9925-8e9690ed447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"unlabeled\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size),\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if args.nodes > 1:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n",
    "    )\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=(train_sampler is None),\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    "    sampler=train_sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8543c5ac-f578-4016-be17-9f143b894452",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_resnet() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41020/1140863459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# init model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_resnet() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "encoder = get_resnet(args.resnet, pretrained=False)\n",
    "n_features = encoder.fc.in_features\n",
    "\n",
    "# init model\n",
    "model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "if args.reload:\n",
    "    model_fp = os.path.join(\n",
    "        args.model_path, f\"checkpoint_{args.epoch_num}.tar\"\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "model = model.to(args.device)\n",
    "optimizer, scheduler = load_optimizer(args, model)\n",
    "criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)\n",
    "writer = SummaryWriter(log_dir='/home/kaipak/models/runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e2b85-96f5-4e6a-b811-ae08038c5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer, writer, display_every=50):\n",
    "    \"\"\"Train function\"\"\"\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for step, ((x_i, x_j), _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "        \n",
    "        # Positive pair with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "        \n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % display_every == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n",
    "        epoch_loss += loss.item()\n",
    "        args.global_step += 1\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7267a-3aa6-44fe-ae2e-29c8f534dd28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    epoch_loss = train(args, train_loader, model, criterion, optimizer, writer)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        save_model(args, model, optimizer)\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {epoch_loss / len(train_loader)}\\t lr: {round(lr, 5)}\"\n",
    "    )\n",
    "    args.current_epoch += 1\n",
    "\n",
    "save_model(args, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86d208-a48d-4276-8905-749d968ada73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69926cf-7e82-47f4-99e3-b1c8f5234ab8",
   "metadata": {},
   "source": [
    "## Linear Evaluation\n",
    "From example, LE using logistic regression, from weights from frozen trained model from previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30d998ea-cd9b-4056-8ea8-3197870bae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer, writer):\n",
    "    \"\"\"Train evaluation model\"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += step_loss\n",
    "        writer.add_scalar(\"Accuracy/train_step\", step_accuracy, args.global_step)\n",
    "        args.global_step += 1\n",
    "        \n",
    "    writer.add_scalar(\"Accuracy/train_epoch\", step_accuracy, args.current_epoch)\n",
    "    writer.add_scalar(\"Loss/train_epoch\", epoch_loss, args.current_epoch)\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "        \n",
    "        output = model(x)\n",
    "        step_loss = criterion(output, y)\n",
    "        \n",
    "        predicted = output.argmax(1)\n",
    "        step_accuracy = (predicted == y).sum().item() / y.size(0)\n",
    "        epoch_accuracy += step_accuracy\n",
    "        \n",
    "        epoch_loss += step_loss.item()\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37515605-43b1-4c6c-8406-f5665ebc62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "use_tpu = False\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"../config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if use_tpu:\n",
    "  args.device = dev\n",
    "else:\n",
    "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args.batch_size = 32\n",
    "args.dataset = \"CIFAR10\"\n",
    "args.resnet = \"resnet50\"\n",
    "args.model_path = \"../../../models/SimCLRv2/save\"\n",
    "args.epoch_num = 100\n",
    "args.logistic_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fb25ab3-c90b-4760-b157-a4fd2a290d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == \"STL10\":\n",
    "    train_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"train\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.STL10(\n",
    "        args.dataset_dir,\n",
    "        split=\"test\",\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        args.dataset_dir,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=TransformsSimCLR(size=args.image_size).test_transform,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fced2b-f6fa-4aa6-bce5-8416da12f7f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.downsample = downsample  # hack: moving downsample to the first to make order correct\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, width_mult=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64 * width_mult\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64 * width_mult, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128 * width_mult, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256 * width_mult, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512 * width_mult, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion * width_mult, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def resnet50x1(**kwargs):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], width_mult=1)\n",
    "\n",
    "def resnet50x2(**kwargs):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], width_mult=2)\n",
    "\n",
    "\n",
    "def resnet50x4(**kwargs):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], width_mult=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee4c42-bb68-49e9-8e8e-c11d2636c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet encoder / SimCLR and load model weights\n",
    "#encoder = get_resnet(args.resnet, pretrained=False)\n",
    "#n_features = encoder.fc.in_features\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "encoder = resnet50x4()\n",
    "encoder.load_state_dict(torch.load('/home/kaipak/models/SimCLRv1/resnet50-4x.pth', map_location='cpu')['state_dict'])\n",
    "n_features = encoder.fc.in_features\n",
    "simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "#model_fp = os.path.join(args.model_path, \"checkpoint_40.pt\")\n",
    "#simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model)\n",
    "\n",
    "simclr_model = simclr_model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99fb4fc5-6d02-4e36-82f2-8b3684742649",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load /home/kaipak/dev/SimCLRv2-Pytorch/resnet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "BATCH_NORM_DECAY = 0.9  # == pytorch's default value as well\n",
    "\n",
    "\n",
    "class BatchNormRelu(nn.Sequential):\n",
    "    def __init__(self, num_channels, relu=True):\n",
    "        super().__init__(nn.BatchNorm2d(num_channels, eps=BATCH_NORM_EPSILON), nn.ReLU() if relu else nn.Identity())\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                     stride=stride, padding=(kernel_size - 1) // 2, bias=bias)\n",
    "\n",
    "\n",
    "class SelectiveKernel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, sk_ratio, min_dim=32):\n",
    "        super().__init__()\n",
    "        assert sk_ratio > 0.0\n",
    "        self.main_conv = nn.Sequential(conv(in_channels, 2 * out_channels, stride=stride),\n",
    "                                       BatchNormRelu(2 * out_channels))\n",
    "        mid_dim = max(int(out_channels * sk_ratio), min_dim)\n",
    "        self.mixing_conv = nn.Sequential(conv(out_channels, mid_dim, kernel_size=1), BatchNormRelu(mid_dim),\n",
    "                                         conv(mid_dim, 2 * out_channels, kernel_size=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main_conv(x)\n",
    "        x = torch.stack(torch.chunk(x, 2, dim=1), dim=0)  # 2, B, C, H, W\n",
    "        g = x.sum(dim=0).mean(dim=[2, 3], keepdim=True)\n",
    "        m = self.mixing_conv(g)\n",
    "        m = torch.stack(torch.chunk(m, 2, dim=1), dim=0)  # 2, B, C, 1, 1\n",
    "        return (x * F.softmax(m, dim=0)).sum(dim=0)\n",
    "\n",
    "\n",
    "class Projection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, sk_ratio=0):\n",
    "        super().__init__()\n",
    "        if sk_ratio > 0:\n",
    "            self.shortcut = nn.Sequential(nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "                                          # kernel_size = 2 => padding = 1\n",
    "                                          nn.AvgPool2d(kernel_size=2, stride=stride, padding=0),\n",
    "                                          conv(in_channels, out_channels, kernel_size=1))\n",
    "        else:\n",
    "            self.shortcut = conv(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        self.bn = BatchNormRelu(out_channels, relu=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(self.shortcut(x))\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, sk_ratio=0, use_projection=False):\n",
    "        super().__init__()\n",
    "        if use_projection:\n",
    "            self.projection = Projection(in_channels, out_channels * 4, stride, sk_ratio)\n",
    "        else:\n",
    "            self.projection = nn.Identity()\n",
    "        ops = [conv(in_channels, out_channels, kernel_size=1), BatchNormRelu(out_channels)]\n",
    "        if sk_ratio > 0:\n",
    "            ops.append(SelectiveKernel(out_channels, out_channels, stride, sk_ratio))\n",
    "        else:\n",
    "            ops.append(conv(out_channels, out_channels, stride=stride))\n",
    "            ops.append(BatchNormRelu(out_channels))\n",
    "        ops.append(conv(out_channels, out_channels * 4, kernel_size=1))\n",
    "        ops.append(BatchNormRelu(out_channels * 4, relu=False))\n",
    "        self.net = nn.Sequential(*ops)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.projection(x)\n",
    "        return F.relu(shortcut + self.net(x))\n",
    "\n",
    "\n",
    "class Blocks(nn.Module):\n",
    "    def __init__(self, num_blocks, in_channels, out_channels, stride, sk_ratio=0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([BottleneckBlock(in_channels, out_channels, stride, sk_ratio, True)])\n",
    "        self.channels_out = out_channels * BottleneckBlock.expansion\n",
    "        for _ in range(num_blocks - 1):\n",
    "            self.blocks.append(BottleneckBlock(self.channels_out, out_channels, 1, sk_ratio))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for b in self.blocks:\n",
    "            x = b(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Stem(nn.Sequential):\n",
    "    def __init__(self, sk_ratio, width_multiplier):\n",
    "        ops = []\n",
    "        channels = 64 * width_multiplier // 2\n",
    "        if sk_ratio > 0:\n",
    "            ops.append(conv(3, channels, stride=2))\n",
    "            ops.append(BatchNormRelu(channels))\n",
    "            ops.append(conv(channels, channels))\n",
    "            ops.append(BatchNormRelu(channels))\n",
    "            ops.append(conv(channels, channels * 2))\n",
    "        else:\n",
    "            ops.append(conv(3, channels * 2, kernel_size=7, stride=2))\n",
    "        ops.append(BatchNormRelu(channels * 2))\n",
    "        ops.append(nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        super().__init__(*ops)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, layers, width_multiplier, sk_ratio):\n",
    "        super().__init__()\n",
    "        ops = [Stem(sk_ratio, width_multiplier)]\n",
    "        channels_in = 64 * width_multiplier\n",
    "        ops.append(Blocks(layers[0], channels_in, 64 * width_multiplier, 1, sk_ratio))\n",
    "        channels_in = ops[-1].channels_out\n",
    "        ops.append(Blocks(layers[1], channels_in, 128 * width_multiplier, 2, sk_ratio))\n",
    "        channels_in = ops[-1].channels_out\n",
    "        ops.append(Blocks(layers[2], channels_in, 256 * width_multiplier, 2, sk_ratio))\n",
    "        channels_in = ops[-1].channels_out\n",
    "        ops.append(Blocks(layers[3], channels_in, 512 * width_multiplier, 2, sk_ratio))\n",
    "        channels_in = ops[-1].channels_out\n",
    "        self.channels_out = channels_in\n",
    "        self.net = nn.Sequential(*ops)\n",
    "        self.fc = nn.Linear(channels_in, 1000)\n",
    "\n",
    "    def forward(self, x, apply_fc=False):\n",
    "        h = self.net(x).mean(dim=[2, 3])\n",
    "        if apply_fc:\n",
    "            h = self.fc(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class ContrastiveHead(nn.Module):\n",
    "    def __init__(self, channels_in, out_dim=128, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            if i != num_layers - 1:\n",
    "                dim, relu = channels_in, True\n",
    "            else:\n",
    "                dim, relu = out_dim, False\n",
    "            self.layers.append(nn.Linear(channels_in, dim, bias=False))\n",
    "            bn = nn.BatchNorm1d(dim, eps=BATCH_NORM_EPSILON, affine=True)\n",
    "            if i == num_layers - 1:\n",
    "                nn.init.zeros_(bn.bias)\n",
    "            self.layers.append(bn)\n",
    "            if relu:\n",
    "                self.layers.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for b in self.layers:\n",
    "            x = b(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_resnet(depth=50, width_multiplier=1, sk_ratio=0):  # sk_ratio=0.0625 is recommended\n",
    "    layers = {50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}[depth]\n",
    "    resnet = ResNet(layers, width_multiplier, sk_ratio)\n",
    "    return resnet, ContrastiveHead(resnet.channels_out)\n",
    "\n",
    "\n",
    "def name_to_params(checkpoint):\n",
    "    sk_ratio = 0.0625 if '_sk1' in checkpoint else 0\n",
    "    if 'r50_' in checkpoint:\n",
    "        depth = 50\n",
    "    elif 'r101_' in checkpoint:\n",
    "        depth = 101\n",
    "    elif 'r152_' in checkpoint:\n",
    "        depth = 152\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if '_1x_' in checkpoint:\n",
    "        width = 1\n",
    "    elif '_2x_' in checkpoint:\n",
    "        width = 2\n",
    "    elif '_3x_' in checkpoint:\n",
    "        width = 3\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return depth, width, sk_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79cacf97-1e42-4577-ab73-a613cc0865d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet encoder / SimCLR and load model weights\n",
    "#encoder = get_resnet(args.resnet, pretrained=False)\n",
    "#n_features = encoder.fc.in_features\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "encoder, head = get_resnet(depth=101, width_multiplier=2, sk_ratio=0.0625)\n",
    "encoder.load_state_dict(torch.load('/home/kaipak/models/SimCLRv2/r101_2x_sk1.pth', map_location='cpu')['resnet'])\n",
    "\n",
    "n_features = encoder.fc.in_features\n",
    "simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "#model_fp = os.path.join(args.model_path, \"checkpoint_40.pt\")\n",
    "#simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  simclr_model_ngpu = nn.DataParallel(simclr_model)\n",
    "  simclr_model_ngpu.n_features = n_features\n",
    "\n",
    "simclr_model = simclr_model_ngpu.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4458865f-1b8f-4b77-93c1-d5879047ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveHead(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (4): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=4096, out_features=128, bias=False)\n",
       "    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2cc6f15-f70d-4ea6-a6de-86e5baddad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62c0cb39-6583-4f79-b2ae-813ffeae4eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "from simclr.modules import LARS\n",
    "\n",
    "n_classes = 10\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "#optimizer = LARS(model.parameters(), lr=3e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(log_dir='/home/kaipak/models/runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ce95cb5-aef8-4edf-b3f1-4f74b94c3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to map all input data X to their latent representations \n",
    "# h that are used in linear evaluation (they only have to be computed once)\n",
    "# Should be part of the processing step before FT.\n",
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, _, z, _ = simclr_model(x, x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2875166-c2ac-4fa1-8bc7-098bfc615ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/195]\t Computing features...\n",
      "Step [20/195]\t Computing features...\n",
      "Step [40/195]\t Computing features...\n",
      "Step [60/195]\t Computing features...\n",
      "Step [80/195]\t Computing features...\n",
      "Step [100/195]\t Computing features...\n",
      "Step [120/195]\t Computing features...\n",
      "Step [140/195]\t Computing features...\n",
      "Step [160/195]\t Computing features...\n",
      "Step [180/195]\t Computing features...\n",
      "Features shape (49920, 4096)\n",
      "Step [0/39]\t Computing features...\n",
      "Step [20/39]\t Computing features...\n",
      "Features shape (9984, 4096)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y, test_X, test_y) = get_features(\n",
    "    simclr_model, train_loader, test_loader, args.device\n",
    ")\n",
    "\n",
    "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "313af8e7-f3ef-4907-ba9f-a1c9ca913055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 7 µs, total: 7 µs\n",
      "Wall time: 13.1 µs\n",
      "Epoch [0/400]\t Loss: 2.2319798469543457\t Accuracy: 0.47682291666666665\n",
      "Epoch [20/400]\t Loss: 2.2054662704467773\t Accuracy: 0.5101762820512821\n",
      "Epoch [40/400]\t Loss: 2.1790452003479004\t Accuracy: 0.526582532051282\n",
      "Epoch [60/400]\t Loss: 2.1526060104370117\t Accuracy: 0.5374399038461538\n",
      "Epoch [80/400]\t Loss: 2.126054525375366\t Accuracy: 0.544491185897436\n",
      "Epoch [100/400]\t Loss: 2.0993082523345947\t Accuracy: 0.5503004807692308\n",
      "Epoch [120/400]\t Loss: 2.0722970962524414\t Accuracy: 0.5547475961538462\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41020/1735950208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#for epoch in range(args.logistic_epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimclr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_41020/1588413338.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, loader, simclr_model, model, criterion, optimizer, writer)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mstep_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/SimCLRv2/simclr/modules/lars.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch, closure)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mg_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mg_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                         ),\n\u001b[1;32m    126\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "args.logistic_epochs = 400\n",
    "\n",
    "#for epoch in range(args.logistic_epochs):\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, arr_train_loader, simclr_model, model, criterion, optimizer, writer)\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "    \n",
    "    args.current_epoch += 1\n",
    "        \n",
    "loss_epoch, accuracy_epoch = test(\n",
    "    args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c95f3e-69af-45a1-8cdf-24ceb2537e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c32a44-f434-4cb4-b2f4-a5d141211ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try converting pretrained weights from Google's TF Implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
